{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from models.tiny import resnet18\n",
    "import os\n",
    "from victim.blackbox import Blackbox\n",
    "import utils.common as common\n",
    "from datasets import sized_transforms\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "# pretrained = \"/mnt/ywb/checkpoints/imagenet/resnet18/resnet18-5c106cde.pth\"\n",
    "\n",
    "model = resnet18()\n",
    "# checkpoint = torch.load(pretrained)\n",
    "# pretrained_state_dict = checkpoint.get(\"state_dict\", checkpoint)\n",
    "# model.load_state_dict(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pretrained_test_D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-90af461d2df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     ),\n\u001b[1;32m     17\u001b[0m     'val': torch.utils.data.DataLoader(\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpretrained_test_D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pretrained_test_D' is not defined"
     ]
    }
   ],
   "source": [
    "from datasets.imagenet64 import ImageNet64 as imagenet\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize([32,32]),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "pretrained_data = imagenet(train=True, transform=transform)\n",
    "pretrained_test_data = imagenet(train=False, transform=transform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        pretrained_data,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    ),\n",
    "    'val': torch.utils.data.DataLoader(\n",
    "        pretrained_test_data,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pretrained_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                if phase == 'val':\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                else:\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nException raised from launch_vectorized_kernel at /pytorch/aten/src/ATen/native/cuda/CUDALoops.cuh:146 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fe07e5cb1e2 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: void at::native::gpu_kernel_impl<__nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> >(at::TensorIterator&, __nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> const&) + 0xe03 (0x7fe032bb9933 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #2: void at::native::gpu_kernel<__nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> >(at::TensorIterator&, __nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> const&) + 0x11b (0x7fe032bbb34b in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #3: void at::native::gpu_kernel_with_scalars<__nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> >(at::TensorIterator&, __nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> const&) + 0xeb (0x7fe032bbb5bb in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0x192a486 (0x7fe032b7d486 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar) + 0x1a (0x7fe032b7e1fa in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0xbce25e (0x7fe068a0d25e in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: at::native::add_out(at::Tensor&, at::Tensor const&, at::Tensor const&, c10::Scalar) + 0x71 (0x7fe068a03b61 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0xf3b932 (0x7fe03218e932 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #9: <unknown function> + 0x2e9fad8 (0x7fe06acdead8 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x3377258 (0x7fe06b1b6258 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: torch::autograd::AccumulateGrad::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x38a (0x7fe06b1b7aaa in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x3375bb7 (0x7fe06b1b4bb7 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fe06b1b0400 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fe06b1b0fa1 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fe06b1a9119 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fe07f37dc8a in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #17: <unknown function> + 0xbd6df (0x7fe09ac516df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #18: <unknown function> + 0x76db (0x7fe0a32b66db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #19: clone + 0x3f (0x7fe0a283aa3f in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8bb1fedb1319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-cb6da153e38d>\u001b[0m in \u001b[0;36mtrain_pretrained_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;31m# backward + optimize only if in training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchenv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchenv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nException raised from launch_vectorized_kernel at /pytorch/aten/src/ATen/native/cuda/CUDALoops.cuh:146 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fe07e5cb1e2 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: void at::native::gpu_kernel_impl<__nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> >(at::TensorIterator&, __nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> const&) + 0xe03 (0x7fe032bb9933 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #2: void at::native::gpu_kernel<__nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> >(at::TensorIterator&, __nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> const&) + 0x11b (0x7fe032bbb34b in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #3: void at::native::gpu_kernel_with_scalars<__nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> >(at::TensorIterator&, __nv_hdl_wrapper_t<false, false, __nv_dl_tag<void (*)(at::TensorIterator&, c10::Scalar), &at::native::add_kernel_cuda, 4u>, float (float, float), float> const&) + 0xeb (0x7fe032bbb5bb in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #4: <unknown function> + 0x192a486 (0x7fe032b7d486 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: at::native::add_kernel_cuda(at::TensorIterator&, c10::Scalar) + 0x1a (0x7fe032b7e1fa in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0xbce25e (0x7fe068a0d25e in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: at::native::add_out(at::Tensor&, at::Tensor const&, at::Tensor const&, c10::Scalar) + 0x71 (0x7fe068a03b61 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #8: <unknown function> + 0xf3b932 (0x7fe03218e932 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cuda.so)\nframe #9: <unknown function> + 0x2e9fad8 (0x7fe06acdead8 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x3377258 (0x7fe06b1b6258 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: torch::autograd::AccumulateGrad::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x38a (0x7fe06b1b7aaa in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x3375bb7 (0x7fe06b1b4bb7 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fe06b1b0400 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fe06b1b0fa1 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fe06b1a9119 in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fe07f37dc8a in /home/ubuntu/torchenv/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #17: <unknown function> + 0xbd6df (0x7fe09ac516df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)\nframe #18: <unknown function> + 0x76db (0x7fe0a32b66db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #19: clone + 0x3f (0x7fe0a283aa3f in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "model = train_pretrained_model(model.cuda(), criterion, optimizer, lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "for param in model.parameters():\n",
    "   param.requires_grad=False\n",
    "model.fc = nn.Linear(64, 43)\n",
    "model = model.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/mnt/ywb/results/victim/gtsrb-blackbox/checkpoint.pth.tar'\n",
      "=> loaded checkpoint (epoch 56, acc=97.81)\n"
     ]
    }
   ],
   "source": [
    "blackbox = Blackbox.from_modeldir('/mnt/ywb/results/victim/gtsrb-blackbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> done loading GTSRB (test) with 12630 examples\n"
     ]
    }
   ],
   "source": [
    "from datasets.gtsrb import GTSRB\n",
    "test_data = GTSRB(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12630/12630 [00:02<00:00, 4633.90it/s]\n"
     ]
    }
   ],
   "source": [
    "test = common.query_dataset(blackbox, test_data, batch_size=64,device=torch.device('cuda'), transform=sized_transforms[32])\n",
    "test.labels = [label.argmax() for label in test.labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_labels = set()\n",
    "selected_indices = []\n",
    "for index, (_, label) in enumerate(data):\n",
    "    if label not in selected_labels:\n",
    "        selected_labels.add(label)\n",
    "        selected_indices.append(index)\n",
    "    if len(selected_labels) >= 1000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 868.10it/s]\n"
     ]
    }
   ],
   "source": [
    "trainset = common.query_dataset(blackbox, data, list_indices=selected_indices,batch_size=64, device=torch.device('cuda'), transform=sized_transforms[32],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "trainset.dataset.dataset.transform = transforms.Compose([\n",
    "        transforms.Resize([32,32]),\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dataset.transform = transforms.Compose([\n",
    "        transforms.Resize([32,32]),\n",
    "#         transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    ),\n",
    "    'val': torch.utils.data.DataLoader(\n",
    "        test,\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    ),\n",
    "}\n",
    "\n",
    "def train_model(model, train_criterion, test_criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                for layer in model.modules():\n",
    "                    if isinstance(layer, nn.BatchNorm2d):\n",
    "                        layer.eval()\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    if phase == 'train':\n",
    "                        loss = train_criterion(outputs, labels)\n",
    "                    else:\n",
    "                        loss = test_criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                if phase == 'val':\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "                else:\n",
    "                    running_corrects += torch.sum(preds == labels.argmax(1))\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sizes = {'train': 1000, 'val': len(test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCE(input, target):\n",
    "    log_probs = torch.nn.functional.log_softmax(input, dim=1)\n",
    "    return -(target * log_probs).sum() / input.shape[0]\n",
    "\n",
    "train_criterion = SCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5000, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 3.0727 Acc: 0.2640\n",
      "val Loss: 3.7173 Acc: 0.0565\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 3.0639 Acc: 0.2640\n",
      "val Loss: 3.7392 Acc: 0.0565\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 3.0578 Acc: 0.2640\n",
      "val Loss: 3.7372 Acc: 0.0565\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 3.0532 Acc: 0.2640\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fc8d755745fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-9b4ecfd80eea>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_criterion, test_criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/torchenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3.7/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python3.7/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(model, train_criterion, criterion, optimizer, lr_scheduler, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 43 artists>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(range(43), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1000))\n",
    "y = np.zeros(43)\n",
    "for _, label in trainset:\n",
    "    y[label.argmax()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([trainset[0][1], trainset[1][1]]).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utils.common.Subset"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.5734,  2.5447,  1.1931,  ...,  0.9234, -0.0713,  0.0810],\n",
       "         [-0.3074,  1.6158,  0.4346,  ...,  0.8405, -0.5293,  0.0873],\n",
       "         [ 0.2750,  1.4432,  1.5153,  ...,  1.0456, -0.2387,  0.7027],\n",
       "         ...,\n",
       "         [ 0.7430,  2.2944,  0.2418,  ...,  0.7948, -0.2294, -0.3633],\n",
       "         [ 0.4993,  1.2861,  0.8116,  ...,  0.9104,  0.1671, -0.2291],\n",
       "         [-0.0836,  2.0858,  1.0087,  ...,  0.5940, -0.4848,  0.0553]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 43])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 43])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1486, -0.1486, -0.1486,  ..., -0.0629, -0.0458, -0.0458],\n",
       "          [-0.1657, -0.1657, -0.1657,  ..., -0.0458, -0.0458, -0.0458],\n",
       "          [-0.1828, -0.1828, -0.1828,  ..., -0.0458, -0.0458, -0.0458],\n",
       "          ...,\n",
       "          [-0.1314, -0.1314, -0.1143,  ..., -0.1486, -0.1486, -0.1486],\n",
       "          [-0.1314, -0.1314, -0.1143,  ..., -0.1486, -0.1486, -0.1486],\n",
       "          [-0.1314, -0.1314, -0.1314,  ..., -0.1486, -0.1314, -0.1314]],\n",
       " \n",
       "         [[ 0.4153,  0.4153,  0.4153,  ...,  0.4678,  0.4678,  0.4678],\n",
       "          [ 0.3978,  0.3978,  0.4153,  ...,  0.4853,  0.4853,  0.4853],\n",
       "          [ 0.3978,  0.3978,  0.3978,  ...,  0.4853,  0.4853,  0.4853],\n",
       "          ...,\n",
       "          [ 0.3277,  0.3277,  0.3277,  ...,  0.3627,  0.3452,  0.3452],\n",
       "          [ 0.3102,  0.3102,  0.3102,  ...,  0.3627,  0.3452,  0.3452],\n",
       "          [ 0.3102,  0.3102,  0.3102,  ...,  0.3452,  0.3452,  0.3452]],\n",
       " \n",
       "         [[ 1.2108,  1.2108,  1.2108,  ...,  1.3154,  1.3154,  1.3154],\n",
       "          [ 1.2108,  1.2108,  1.2108,  ...,  1.3328,  1.3328,  1.3328],\n",
       "          [ 1.1934,  1.1934,  1.1934,  ...,  1.3328,  1.3328,  1.3328],\n",
       "          ...,\n",
       "          [ 1.0365,  1.0365,  1.0365,  ...,  1.1237,  1.1062,  1.1062],\n",
       "          [ 1.0539,  1.0539,  1.0539,  ...,  1.1237,  1.1062,  1.1062],\n",
       "          [ 1.0714,  1.0714,  1.0539,  ...,  1.1062,  1.1062,  1.1062]]]),\n",
       " tensor(16))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
